### Project #1 - Wikipedia to CSV File

In this project, we aim to extract data from the Wikipedia page listing the top 100 largest companies in the world and save it into a CSV file.

**Tools and Libraries:**
- Python
- Jupyter Notebook
- Beautiful Soup
- Requests
- Pandas

**Link to Wikipedia page:** [List of largest companies in the United States by revenue](https://en.wikipedia.org/wiki/List_of_largest_companies_in_the_United_States_by_revenue)

### How to Test:

1. **Fork the Repository:**
   Fork the repository to your GitHub account by clicking the "Fork" button at the top right of the repository page.

2. **Clone the Repository:**
   Clone the forked repository to your local machine. You can do this by running the following command in your terminal or command prompt:

3. **Launch it via IDE (VSCode) and run it with Jupyter Notebook.

4. ** Things to change: 
            - change the output location in the last line.

   ```bash
   git clone https://github.com/kru2710shna/Project#1_Wiki_Largest_Comp_Data.git
